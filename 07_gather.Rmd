---
title: "Gathering main findings, tables and figures  for TNC-NTRI rangeland management project publication"
author: |
  | Stefan Gehrig
  | www.estimact.com / estimact@onmail.com
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  bookdown::pdf_document2:
    extra_dependencies: ["float"]
    fig_caption: yes
    latex_engine: xelatex
    number_sections: yes
    toc: no
header-includes:
  \usepackage[colorlinks]{hyperref}
  \AtBeginDocument{
  \hypersetup{
    linkcolor=Blue}}
  \pagenumbering{gobble}
  \usepackage{fontspec}
  \usepackage{float}
  \floatplacement{figure}{H}
  \usepackage{natbib}
  \setmainfont{Segoe UI Light}
  \usepackage{xfrac}
  \usepackage{bm}
  \usepackage{amsmath}
  \usepackage[left]{lineno}
  \usepackage{pdflscape}
  \usepackage[labelfont=bf]{caption}
  \newcommand{\blandscape}{\begin{landscape}}
  \newcommand{\elandscape}{\end{landscape}}
  \setlength{\tabcolsep}{4pt}
  \usepackage{titling}
  \pretitle{\begin{center}
  \vspace{-2.5cm}
  \includegraphics[height=1.25cm]{utils/estimact.png}
    \vspace{0.85cm}\LARGE\\}
  \posttitle{\end{center}}
  \usepackage{setspace}
  \singlespacing
  \usepackage{fancyhdr}
  \usepackage{fancybox}
  \pagestyle{fancy}
  \fancyhead{}
fontsize: 10pt
bibliography: utils/refs.bib
urlcolor: blue
geometry: top=1in, bottom=1in, left=1in, right=1in
---

\fancyhead[C]{www.estimact.com / estimact@onmail.com}

\vspace{0.5cm}

*Data:* https://stefgehrig.shinyapps.io/TNC-NTRI/   
*Code:* https://github.com/stefgehrig/rangeland 

\vspace{0.25cm}

In line with the comments received and discussions had (e-mail from Monique, 2023-08-05), here we are starting to collect and results, tables and figures which could make it into the main text or supplemental material (SM) of the manuscript that Monique et al. will be preparing. The previous delivery of results (my e-mail from 2023-07-24) contained a more diverse set of explorations and presentations, but at this stage, we are ready to zoom in again on the relevant paths of analysis to be pursued and a reduced set of ways to present the results. This helps to gain structure and reduce confusion.

\vspace{0.25cm}

```{=latex}
\tableofcontents
```
 
\newpage \pagenumbering{arabic} \setcounter{page}{1}
 
```{r setup, include=FALSE}
library(knitr)
library(kableExtra)
library(tidyverse)
library(brms)
library(dagitty)
library(ggdag)
knitr::opts_chunk$set(echo = FALSE)

gat_tab1 <- readRDS("outputs/gat_tab1.rds")
gat_tab2 <- readRDS("outputs/gat_tab2.rds")
```

\textcolor{red}{schau nochmal in den NTRI (!) report, das Word doc. Da sind viele wertvolle richtungen zu denken drin mit dem ganzen substantivem wissen Ã¼ber den Ort und so und den Fragen die sie analysieren.}

# Descriptive tables and figures

It would make sense to split the data we use in two "types" and also present them in that way, to be very clear to readers. The first type are those Diagnostic Framework (DF) variables that are constructed from interviews and focus groups and coded in binary / ordinal manner (and used as outcome or predictor). These are noisy measurements of underlying latent traits and that is also the way we treat them in the analysis. One way to present them (main text or SM) is for example Table \ref{tab:dfsum}, based on the DF in the version from @mcginnis_social-ecological_2014. I'd suggest to only present the DF variables which actually use for the analysis, which is the logic I followed here.^[Of course, a full list of DF variables collected during the project could still go in the SM. But there are some variables that we cannot make good use of for the current analysis and they would maybe distract.] This reduction of DF variables from the full set to a reduced set could become a methodological side-story of the manuscript: The full DF is a very mixed bag and not per se a suitable tool for impact assessments or analyzing pathways of change -- but it a quite massively filled bag from which one can draw subsets for more targeted research questions.

```{r dfsum}
dfsum <- gat_tab1 %>% 
  mutate(bin = ifelse(bin==TRUE, "*", " "),
         tier1 = droplevels(tier1)) 

dfsum %>% 
  select(-tier1) %>% 
  kable(
    booktabs = TRUE,
     linesep = "",
    caption = "DF variables used in the analysis and their response distributions in the 12 villages. The asterik indicates whether a variable has originally been coded as binary and was therefore transformed to only have response options 1 and 3 (i.e., no middle option).",
    col.names = c("Third-tier variable", "1", "2", "3", " ", "Explanation of highest score"),
    ) %>% 
  kable_styling(font_size = 5.5, latex_options = "HOLD_position") %>% 
  add_header_above(c(" " = 1, "Score\nfrequency" = 3, " " = 2)) %>% 
  kableExtra::group_rows(index = table(dfsum$tier1))
```


Then, there is the second type of data we use in the current analysis, which is *everything measured on a continuous scale* (and used as outcome or predictor). These data cannot be easily pooled with the data from Table \ref{tab:dfsum}, because they live on a different scale. The different ways to bring them on comparable scales for presentations (see previous reports) are not really ideal. Some of these other variables might correspondent to a DF dimension, but we separate them conceptually from the variables in Table \ref{tab:dfsum} due to the way they are measured and due to the role they play in the analysis. They are summarized in Table \ref{tab:othersum}.^[For economic inequality, we estimate the within-village SD from the first PC of a PCA on household assets based on the household survey [following @sharma_escalation_2023]. These assets include the availability/quality of wall, floor, roof, toilet, mobile phone, motorcycle and bed. As quick check of validity, the resuling score strongly correlates with the proportion of people in a village having a motorcycle ($r \approx 0.7$), which in this local context could be a simple indicator of wealth inequality.]

```{r othersum}
gat_tab2 %>% 
  kable(
    booktabs = TRUE,
    digits = 2,
     linesep = "",
    caption = "Other, continuously measured variables used in the analysis and their response distributions in the 12 villages.",
    col.names = c("Variable", "Mean", "Min", "Max", "Source"),
    ) %>% 
  kable_styling(font_size = 8, latex_options = "HOLD_position")%>% 
  add_header_above(c(" " = 1, "Distribution" = 3, " " = 1)) 
```


A natural way to visualize  for all villages the data in Table \ref{tab:dfsum} is via spider plots (Figure \ref{fig:radar}), for Table \ref{tab:othersum} it is via stripe / box plots (Figure \ref{fig:boxes}).

\newpage

```{r radar, fig.align='center', fig.cap='Village-level spider plots of scores for all DF variables from Table 1, split by whether they refer to outcome dimensions (right) or not (left).', out.width="100%"}
include_graphics("outputs/gat_spiders.png")
```

\newpage

```{r boxes, fig.align='center', fig.cap='Boxplots for variables from Table 2. In the horizontal direction, positions are randomly scattered.', out.width="100%"}
include_graphics("outputs/gat_boxes.png")
```

\newpage

# Item response modeling: Relation between self-reported governance processes and outcomes

This whole section is more or less completely drafted and open to discussion. The figures are not yet final and their layout and readability will be improved for publication.

## Motivation

We now model the association between governance processes and governance outcomes as reported by communities. This is based on the data presented in Table \ref{tab:dfsum}. The workhorse of the analysis will be a Bayesian Item Response Model fit with `brms` [@burkner_bayesian_2020; @fox_bayesian_2010]. 

Item Response Theory (IRT) is a statistical modeling paradigm from psychology that aims to simultaneously assess respondent-level and item-level influences on test scores [@linden_handbook_1997]. It can be viewed as a form of statistical adjustment for item characteristics that allows inference about unobserved latent characteristics of respondents. In our research context, the "respondents" are communities and the items are coded responses from in-depth focus group discussions and interviews. Therefore, in the context of this analysis, we also refer to the third-tier DF variables in Table \ref{tab:dfsum} as items. 

Based on the nature of our items, we a priori propose two underlying latent traits of communities: The quality of the governance process and the quality of the governance outcome. We briefly call the two dimensions *Governance* and *Outcome*. The former is measured by the type of items that refer to governance processes -- all third-tier variables in Table \ref{tab:dfsum} listed under the first-tier categories *Resource Systems (RS)*, *Governance Systems (GS)*, *Actors (A)* and *Interactions (I)*. The latter is measured by the type of items that measure governance outcomes -- listed in Table \ref{tab:dfsum} under the first-tier category *Outcomes (O)*.^[Even though the DF does not put all of these variables into the *Governance Systems (GS)* category, they arguably reflect commons governance processes.] This distinction between these two item types is made on conceptual grounds and in line with the goal to assess the association between governance processes and governance outcomes.

Variation in item responses between villages is assumed to partially reflect true variation in the underlying latent traits of villages, but also measurement error. At the same time, the IRT models will allow to model variation in responses between items due to item *easiness* (the characteristic of an item to produce higher responses by villages) and item *discrimination* (the characteristic of an item to produce responses that allow to distinguish better between villages of different governance process or outcome quality). Such variation is clearly suggested already by the raw data (see Table \ref{tab:dfsum}). Thus, IRT can provide a comprehensive picture of different sources of variation in item responses. Most importantly for our purpose, the model will allow to estimate the positioning of all villages on the two latent dimensions *Governance* and *Outcome*, as well as the correlation across dimensions.

Fitting the IRT model in a Bayesian framework provides a natural way to induce regularization via prior distributions and to quantify and present uncertainty. Due to the rather small sample of villages and the inherent tendency of IRT models to have a high number of parameters to be estimated from data, these aspects are both important in the present analysis. Bayesian IRT models have been gaining popularity in social-ecological research for analyzing imperfectly measured traits of natural resource users [e.g., @pretelli_rates_2022]. 

## Formal model definition

Response of village $j = 1,...,J$ on item $i = 1, ..., I$ shall be denoted as $Y_{i,j}$. Since these scores can take discrete values $k = 1,2,3$, we assume a multinomial distribution of item responses 

$$Y_{i,j} \sim \text{Multinomial}(\pi_{1, i, j}, \pi_{2, i, j}, \pi_{3, i, j})$$

where $\pi_{k, i, j}$ denotes the probability of village $j$ to choose response $k$ on item $i$. Note that $\pi_{1, i, j} + \pi_{2, i, j}+ \pi_{3, i, j} = 1$ for all $i,j$.

Given the ordinal nature of the items responses, we use the cumulative logit link with common slopes.^[In IRT terminology, such models are known as "Graded Response Models" [@linden_handbook_1997].] Accordingly, the probability to give response $k$ or less can can be written as a function of a category-specific threshold parameter $\beta_k$ and a linear combination of village- and item-level characteristics $\eta_{i,j}$, which will ultimately be of substantive interest to us. Higher values of $\eta_{i,j}$ mean a higher expected response category. Further, an item-specific discrimination parameter $a_i$ controls the magnitude of the effect that any predictors have on the response distribution for that item. This leads to

$$
P(Y_{i,j} \leq k) = \text{logit}^{-1} \left(\text{exp}(\alpha + a_i) ( \beta_k - \eta_{i,j} ) \right), 
$$

where $\alpha$ is an intercept parameter for item discrimination, such that $a_i$ represent deviations from mean discrimination for each item. Via including $a_i$, we acknowledge that items do not have constant discrimination. In IRT terminology, this leads to the so-called "two-parameter model" [@linden_handbook_1997], since an additional item-level parameter besides item easiness (or, difficulty, see below) is introduced.^[The discrimination parameter can be understood as an effect modifier. Due to the multiplicativeness of this relationship, the two-parameter model is no more linear in the parameters.] By exponentiating $(\alpha + a_i)$, discrimination is always positive. Put differently, discrimination is modeled on the log-scale, which is the conventional implementation in `brms` [see @burkner_bayesian_2020].

The probabilities to give responses $k = 1,2,3$ can hence be written as

\begin{align*}
\pi_{1, i, j} & = P(Y_{i,j} = 1) = \text{logit}^{-1}\left(\text{exp}(\alpha + a_i) ( \beta_1 - \eta_{i,j} ) \right), \\
\pi_{2, i, j} & = P(Y_{i,j} = 2) = \text{logit}^{-1}\left(\text{exp}(\alpha + a_i) ( \beta_2 - \eta_{i,j} ) \right) - \pi_{1, i, j}, \\
\pi_{3, i, j} & = P(Y_{i,j} = 3) = 1 - \pi_{2, i, j} - \pi_{1, i, j},
\end{align*}

Most importantly, $\eta_{i,j}$ shall be affected by $\theta_j^{\text{Gov}}$ and $\theta_j^{\text{Out}}$. These parameters describe the quality of governance processes and of outcomes in village $j$, respectively. Note that here we are ultimately interested in their correlation parameter $\rho_{\text{Gov},\text{Out}}$. In line with the IRT framework, we will model $\eta_{i,j}$ also as a function of easiness of the item, $b_i$. Accordingly, we write


$$\eta_{i,j} = b_i + \theta_j^{\text{Gov}} \text{Gov}_i + \theta_j^{\text{Out}} \text{Out}_i ,$$
where $\text{Gov}_i$ is an indicator that is 1 if item $i$ is of type *Governance* and 0 otherwise. $\text{Out}_i$ is an indicator that is 1 if item $i$ is of type *Outcome* and 0 otherwise.

Finally, working in a Bayesian framework with varying parameters, we assume that item- and village-level parameters follow the distributions

\begin{align*}
(a_i, b_i)^{t} & \sim \text{Normal}(\bm{0}, D_1), \text{with} \\ 
& D_1 =
\begin{pmatrix}
\sigma^2_{a} & \sigma_{a,b}\\
\sigma_{a,b} & \sigma^2_{b}
\end{pmatrix}, \\ \\
(\theta_j^{\text{Gov}}, \theta_j^{\text{Out}})^{t} & \sim \text{Normal}(\bm{0}, D_2), \text{with} \\ 
& D_2 =
\begin{pmatrix}
\sigma^2_{\text{Gov}} & \sigma_{\text{Gov},\text{Out}}\\
\sigma_{\text{Gov},\text{Out}} & \sigma^2_{\text{Out}}
\end{pmatrix}.
\end{align*}

This implies that the two item parameters $a_i$ and $b_i$ are allowed to covary. Accounting for within-item dependencies in this way is usually desirable in IRT modeling [@fox_bayesian_2010]. Likewise, the two village-parameters $\theta_j^{\text{Gov}}$ and $\theta_j^{\text{Out}}$, follow a bivariate normal distribution with covariance $\sigma_{\text{Gov},\text{Out}}$. We can hence define our parameter of interest, the correlation between governance and outcome quality, based on the IRT model as 

$$\rho_{\text{Gov},\text{Out}} = \frac{\sigma_{\text{Gov},\text{Out}}}{\sigma_{\text{Gov}} \sigma_{\text{Out}}}.$$


By choosing hierarchical priors that induce some shrinkage to the empirical mean, above IRT model becomes a Bayesian hierarchical model. Such pooling of information can lead to improved estimation of respondent and item parameters in IRT models [@fox_bayesian_2010; @burkner_bayesian_2020]. Specifically, we work with the following priors:

\begin{align*}
\alpha & \sim \text{Normal}(0,1), \\
\sigma_a & \sim \text{Exponential}(1.5), \\
\sigma_b & \sim \text{Exponential}(1.5), \\
\begin{pmatrix} 1 & \rho_{a,b} \\ \rho_{a,b} & 1 \end{pmatrix} & \sim \text{LKJCorr}(1), \\
\begin{pmatrix} 1 & \rho_{\text{Gov},\text{Out}} \\ \rho_{\text{Gov},\text{Out}} & 1 \end{pmatrix} & \sim \text{LKJCorr}(1), \\
\beta_1 & \sim \text{Normal}(0, 2.5), \\
\beta_2 & \sim \text{Normal}(0, 2.5). \\
\end{align*}

In addition, the variances of the latent village characteristics are assumed as $\sigma^2_{\text{Gov}} = \sigma^2_{\text{Out}} = 1$, which we can interpret as a prior with all mass in one point. This is a common restriction in IRT to ensure identifiability of the model. These priors simply fix the metric of the latent village characteristics to a standard normal distribution [@fox_bayesian_2010, p. 88; @burkner_bayesian_2020].

In summary, our priors are chosen to have some regularizing influence on the parameters, ensuring model convergence and stability of estimates against the background of relatively sparse data, the occurrence of items with little to no variability between villages (see Table \ref{tab:dfsum}), and a rather richly parametrized model. For example, above exponential priors on the SD of both item parameters put most prior probability ($\approx$ `r round(pexp(1, 1.5), 2)`) on the SD being $\leq 1$ on the logit scale, but also allows for larger values.

## Results

Model convergence was acceptable -- judged by inspecting trace plots and R hat statistics -- and posterior predictive checks in Figure \ref{fig:ppds} indicate a good model fit to the data. It is also visible that the model-based distributions tend to be less extreme, which is partially a consequence of shrinkage, partially of the fact that a logit link function will never strictly assign a probability zero to an outcome.

```{r ppds, fig.align='center', fig.cap='Posterior predictions vs. observed response distributions by item (a) and by village (b).', out.width="100%"}
include_graphics("outputs/ppcs_fit_irt_2par.png")
```

Figure \ref{fig:riestims} shows posteriors for all item- and village-level characteristics (posterior median and equal-tailed 50\% and 90\% credible intervals).

```{r riestims, fig.align='center', fig.cap='Village and item parameter posterior distributions.', out.width="100%"}
include_graphics("outputs/param_posts_fit_irt_2par.png")
```

Of primary interest is the correlation of the two latent village characteristics governance process quality and governance outcome quality. Figure \ref{fig:cor} shows the respective posterior distributions.

```{r cor, fig.align='center', fig.cap='Correlation among latent village characteristics as estimated from the item response model: (a) posterior distribution of the correlation parameter with equal-tailed 90\\% credible interval; (b) Bivariate 90\\% posteriors for each village visualized as contours in the latent characteristic space.', out.width="100%"}
include_graphics("outputs/cor_itm_fit_irt_2par.png")
```

\textcolor{red}{to-do}

- summary / interpretation sentence; also say that poerstiots can be used later. and respect uncertainty compared to averaging.

- no adjustemnt --> interpretation

- high discrimination = steep slope between latent quality and highest response category probability (= LOWER sd of item? that's what is suggested by beurkner ordinal paper); wie related das zu variability in items in raw data und warum?

# Modeling remote sensing outcomes as a result of governance processes

- extend the dag 

    - to include the relationship modelled above in previous section. So there is one effect from GOV to outcome Remote Sensing, and one to outcome Item Responses
    - confounding arrows for BOTH of these relationships, and explain that we will never be able to resolve these. --> but we can use the DAG to de-bias the second estimation from other influenes (e.g., invasices, agriculture), just not from the fundamental problem of endogeneity of treatment assignment (selection of program villages by outsiders + "selection" of governance quality by villagers)

- make sure that these are (mostly) mututally exclusive, which is an assumption I used and monique shares: "I assume maize wheat and bean fields dont look bare in a satelite image". We asked Nathaniel. Maybe we need to look into the polygon files. also see moniques references and paper sent via mail

- add to dag an edge from rainfall to governance: "I guess pastoralist (PA) institutions breakdown where rainfall makes agriculture and option, and possibly where rainfall makes outsiders beg for grazing."

- maybe extend dag: "The DAG starting page 20 on bare ground looks pretty good to me, but I think weâd need a zoom session with Majory and Susan where you explain it, as they are more likely to think of additional paths/variables than I am."

# Modeling wealth outcomes as a result of governance processes

- wealth inequality from PCA, for example @sharma_escalation_2023.

- "but I did think (again initially) it would be nice to have a measure of wealth (averaged across households) and inequality in wealth. I could think about this more if I wer to turn back to the original data, but now. But having wealth and inequality in wealth as an outcomes measure woud be kind of cool. I know its weak, as it is also something of a predictor variable f success (presumably), and without a longitudinal perspective inference is weak, but even with those prosvisos it might be worth including in the current modelling structure as a village level âoutcomeâ."

# Governance processes and outcomes under disturbances

- "it would be good to look at interactins and/or mediations with disturbances, and I agree rainfall, ethnic/econ heterogeneity, and pop growth are all good candidates, if handled separately"

- "external threats could be added to the disturbance analysis discussed earlier â worth doing, even if only ends up in SM so we can say in the the MS that we examined disturbances."

- rainfall variability can also be used: "Pastoralist scholars are oftn mre concerned about rainfall unpredictabiilty and variability than mean amount, but under the current circumstances of increasing drought, this measure may be fine for us. I will keep my eyes open for how rainfall is being used in recent paper"

- there is a hypothesis why rainfall might cause worse pastoralist governacne processes and outcomes: "I guess pastoralist (PA) institutions breakdown where rainfall makes agriculture and option, and possibly where rainfall makes outsiders beg for grazing." and it could lead to discussion like: "'Is agriculture a feasible livelihood option?'. It might lead on from the finding (prelim pr page 12 descriptive analysis) that rainfall has neg effects on governance, on the logic that if PA institutions suffer in wetter areas, what is the logic for mving to agric. [Very politically un PC, but possibly worth investigating for the area]."

# Comparing remote sensing outcomes with a control group

- "might require some sort of âsynthetic counterfactualâ. Quite how we deal with the fact that NTRI presumably selected the villages for intervention on the basis of some criteria will take some thought. Initially Susan or Majory could help us here. I am not sure that our 12 villages comprise the full set of NTRI targets â this would help us enormously with developing controls for GIS."

# References



